{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1 - Installing Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:39:35.245132Z",
     "iopub.status.busy": "2025-05-05T11:39:35.244687Z",
     "iopub.status.idle": "2025-05-05T11:42:41.457639Z",
     "shell.execute_reply": "2025-05-05T11:42:41.456627Z",
     "shell.execute_reply.started": "2025-05-05T11:39:35.245114Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q unsloth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2 - Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:43:54.005641Z",
     "iopub.status.busy": "2025-05-05T11:43:54.005359Z",
     "iopub.status.idle": "2025-05-05T11:44:24.539488Z",
     "shell.execute_reply": "2025-05-05T11:44:24.538917Z",
     "shell.execute_reply.started": "2025-05-05T11:43:54.005602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from unsloth import FastLanguageModel\n",
    "from trl import SFTTrainer \n",
    "from unsloth import is_bfloat16_supported \n",
    "from huggingface_hub import login\n",
    "from transformers import TrainingArguments \n",
    "import wandb\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3 - Loading Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:45:05.654845Z",
     "iopub.status.busy": "2025-05-05T11:45:05.654131Z",
     "iopub.status.idle": "2025-05-05T11:45:05.671184Z",
     "shell.execute_reply": "2025-05-05T11:45:05.670481Z",
     "shell.execute_reply.started": "2025-05-05T11:45:05.654822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "# general configuration\n",
    "HGF = config['general']['HGF']\n",
    "WNB = config['general']['WNB']\n",
    "\n",
    "# outputs\n",
    "output_model_online = config['outputs']['output_model_online_Rec']\n",
    "output_model_local = config['outputs']['output_model_local_Rec']\n",
    "\n",
    "# model\n",
    "base_model = config['model']['base_model']\n",
    "max_seq_length = config['model']['max_seq_length']\n",
    "load_in_4bit = config['model']['load_in_4bit']\n",
    "\n",
    "# lora_config\n",
    "r = config['lora_config']['r']\n",
    "\n",
    "# fine_tuning\n",
    "dataset_num_proc = config['fine_tuning']['dataset_num_proc']\n",
    "per_device_train_batch_size = config['fine_tuning']['per_device_train_batch_size']\n",
    "gradient_accumulation_steps =  config['fine_tuning']['gradient_accumulation_steps']\n",
    "epochs =  config['fine_tuning']['epochs']['recommender']\n",
    "max_steps = config['fine_tuning']['max_steps']\n",
    "warmup_steps = config['fine_tuning']['warmup_steps']\n",
    "learning_rate = config['fine_tuning']['learning_rate']\n",
    "optim = config['fine_tuning']['optim']\n",
    "weight_decay = config['fine_tuning']['weight_decay']\n",
    "lr_scheduler_type = config['fine_tuning']['lr_scheduler_type']\n",
    "output_dir = config['fine_tuning']['output_dir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4 - Reading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:47:37.250854Z",
     "iopub.status.busy": "2025-05-05T11:47:37.250581Z",
     "iopub.status.idle": "2025-05-05T11:47:37.337735Z",
     "shell.execute_reply": "2025-05-05T11:47:37.337114Z",
     "shell.execute_reply.started": "2025-05-05T11:47:37.250838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"Data/MIND-Preprocessed/train.csv\", index_col=0)\n",
    "valid_df = pd.read_csv(\"Data/MIND-Preprocessed/valid.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:47:52.610844Z",
     "iopub.status.busy": "2025-05-05T11:47:52.610189Z",
     "iopub.status.idle": "2025-05-05T11:47:52.619196Z",
     "shell.execute_reply": "2025-05-05T11:47:52.618628Z",
     "shell.execute_reply.started": "2025-05-05T11:47:52.610822Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>history</th>\n",
       "      <th>candidate</th>\n",
       "      <th>label</th>\n",
       "      <th>Description</th>\n",
       "      <th>COT</th>\n",
       "      <th>Targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H1: Panera Bread worker fired after TikTok exp...</td>\n",
       "      <td>C1: Nikki Haley claims top aides tried to recr...</td>\n",
       "      <td>C5</td>\n",
       "      <td>The user appears to be interested in a diverse...</td>\n",
       "      <td>Here's a step-by-step chain of thought leading...</td>\n",
       "      <td>C5, C1, C6, C7, C3, C2, C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H1: Woman, suspect dead at 'Tarzan' actor Ron ...</td>\n",
       "      <td>C1: Chrissy Teigen's weekend was basically a c...</td>\n",
       "      <td>C9</td>\n",
       "      <td>Based on their reading history, the user appea...</td>\n",
       "      <td>Here's a step-by-step chain of thought leading...</td>\n",
       "      <td>C9, C1, C3, C5, C8, C2, C10, C4, C6, C7, C11, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H1: Off to the World Series, these Nationals h...</td>\n",
       "      <td>C1: Carrie Underwood Praises Miranda Lambert a...</td>\n",
       "      <td>C7</td>\n",
       "      <td>The user seems to have a diverse interest in n...</td>\n",
       "      <td>Here's a step-by-step chain of thought leading...</td>\n",
       "      <td>C7, C6, C1, C3, C5, C2, C4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             history  \\\n",
       "0  H1: Panera Bread worker fired after TikTok exp...   \n",
       "1  H1: Woman, suspect dead at 'Tarzan' actor Ron ...   \n",
       "2  H1: Off to the World Series, these Nationals h...   \n",
       "\n",
       "                                           candidate label  \\\n",
       "0  C1: Nikki Haley claims top aides tried to recr...    C5   \n",
       "1  C1: Chrissy Teigen's weekend was basically a c...    C9   \n",
       "2  C1: Carrie Underwood Praises Miranda Lambert a...    C7   \n",
       "\n",
       "                                         Description  \\\n",
       "0  The user appears to be interested in a diverse...   \n",
       "1  Based on their reading history, the user appea...   \n",
       "2  The user seems to have a diverse interest in n...   \n",
       "\n",
       "                                                 COT  \\\n",
       "0  Here's a step-by-step chain of thought leading...   \n",
       "1  Here's a step-by-step chain of thought leading...   \n",
       "2  Here's a step-by-step chain of thought leading...   \n",
       "\n",
       "                                             Targets  \n",
       "0                         C5, C1, C6, C7, C3, C2, C4  \n",
       "1  C9, C1, C3, C5, C8, C2, C10, C4, C6, C7, C11, ...  \n",
       "2                         C7, C6, C1, C3, C5, C2, C4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5 - Authentication & Experiment Tracking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:47:56.683472Z",
     "iopub.status.busy": "2025-05-05T11:47:56.683223Z",
     "iopub.status.idle": "2025-05-05T11:48:09.450197Z",
     "shell.execute_reply": "2025-05-05T11:48:09.449458Z",
     "shell.execute_reply.started": "2025-05-05T11:47:56.683455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "login(HGF)\n",
    "wandb.login(key=WNB)\n",
    "run = wandb.init(\n",
    "    project = \"News-Recommender-MIND-LAST-VR-3-5-2025\",\n",
    "    name = \"20-epochs\",\n",
    "    job_type=\"training\",\n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6 - Loading DeepSeek R1 : Model & Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:48:33.256961Z",
     "iopub.status.busy": "2025-05-05T11:48:33.256437Z",
     "iopub.status.idle": "2025-05-05T11:49:41.319951Z",
     "shell.execute_reply": "2025-05-05T11:49:41.319421Z",
     "shell.execute_reply.started": "2025-05-05T11:48:33.256938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = base_model,\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    token = HGF\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7 - Setting Up Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:50:48.578081Z",
     "iopub.status.busy": "2025-05-05T11:50:48.577847Z",
     "iopub.status.idle": "2025-05-05T11:50:48.632188Z",
     "shell.execute_reply": "2025-05-05T11:50:48.631684Z",
     "shell.execute_reply.started": "2025-05-05T11:50:48.578066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temp_1 = Dataset.from_pandas(train_df)\n",
    "temp_2 = Dataset.from_pandas(valid_df)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": temp_1,\n",
    "    \"validation\": temp_2,\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:50:48.632951Z",
     "iopub.status.busy": "2025-05-05T11:50:48.632774Z",
     "iopub.status.idle": "2025-05-05T11:50:48.638729Z",
     "shell.execute_reply": "2025-05-05T11:50:48.638011Z",
     "shell.execute_reply.started": "2025-05-05T11:50:48.632937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:50:48.639934Z",
     "iopub.status.busy": "2025-05-05T11:50:48.639501Z",
     "iopub.status.idle": "2025-05-05T11:50:48.656209Z",
     "shell.execute_reply": "2025-05-05T11:50:48.655684Z",
     "shell.execute_reply.started": "2025-05-05T11:50:48.639918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns([\"history\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_style = \"\"\" Below is an instruction that describes a task, paired with an input that provied further context.\n",
    "Write a response that appropiately completes the request.\n",
    "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
    "\n",
    "### Instruction:\n",
    "You serve as a personalized news article recommendation system. Based on the user's preference descriptions below and the candidate articles, rank the candidates using their labels.\n",
    "Output Format:\n",
    "Ranked News Articles: <START> C#, C#, ..., C# <END>\n",
    "\n",
    "### Preferences Description:\n",
    "{}\n",
    "\n",
    "### Candidates:\n",
    "{}\n",
    "\n",
    "\n",
    "### Response:\n",
    "<think>\n",
    "{}\n",
    "</think>\n",
    "Ranked News Articles : {}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:50:48.657882Z",
     "iopub.status.busy": "2025-05-05T11:50:48.657695Z",
     "iopub.status.idle": "2025-05-05T11:50:48.670172Z",
     "shell.execute_reply": "2025-05-05T11:50:48.669594Z",
     "shell.execute_reply.started": "2025-05-05T11:50:48.657867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    desc = examples[\"Description\"]\n",
    "    candidates = examples[\"candidate\"]\n",
    "    cots = examples[\"COT\"]\n",
    "    outputs = examples[\"Targets\"]\n",
    "    prompts = []\n",
    "    for des, can, cot, output in zip(desc, candidates, cots, outputs):\n",
    "        prompt = prompt_style.format(des, can, cot, output) + EOS_TOKEN\n",
    "        prompts.append(prompt)\n",
    "    return {\n",
    "        \"prompt\": prompts,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:50:48.670962Z",
     "iopub.status.busy": "2025-05-05T11:50:48.670771Z",
     "iopub.status.idle": "2025-05-05T11:50:48.737556Z",
     "shell.execute_reply": "2025-05-05T11:50:48.737010Z",
     "shell.execute_reply.started": "2025-05-05T11:50:48.670948Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_finetune = dataset.map(formatting_prompts_func, batched = True)\n",
    "dataset_finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8 - Setting up the model using LORA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:50:48.738381Z",
     "iopub.status.busy": "2025-05-05T11:50:48.738176Z",
     "iopub.status.idle": "2025-05-05T11:50:56.238062Z",
     "shell.execute_reply": "2025-05-05T11:50:56.237325Z",
     "shell.execute_reply.started": "2025-05-05T11:50:48.738366Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.4.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model_lora = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = r,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,  \n",
    "    bias=\"none\",  \n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=777,\n",
    "    use_rslora=False,  \n",
    "    loftq_config=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **9 - Fine-Tuning: Setup and Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:50:56.239302Z",
     "iopub.status.busy": "2025-05-05T11:50:56.239014Z",
     "iopub.status.idle": "2025-05-05T11:51:00.665562Z",
     "shell.execute_reply": "2025-05-05T11:51:00.664931Z",
     "shell.execute_reply.started": "2025-05-05T11:50:56.239280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model_lora,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset_finetune['train'],\n",
    "    eval_dataset=dataset_finetune['validation'],\n",
    "    dataset_text_field=\"prompt\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=dataset_num_proc,\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        num_train_epochs=epochs,\n",
    "        max_steps=max_steps,\n",
    "        warmup_steps=warmup_steps,\n",
    "        learning_rate=learning_rate,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=20,\n",
    "        optim=optim,\n",
    "        weight_decay= weight_decay,\n",
    "        lr_scheduler_type=lr_scheduler_type,\n",
    "        seed=777,\n",
    "        output_dir=output_dir,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T11:51:00.666709Z",
     "iopub.status.busy": "2025-05-05T11:51:00.666483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_lora.push_to_hub(output_model_online) \n",
    "tokenizer.push_to_hub(output_model_online)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **11 - Saving Locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(output_model_local) \n",
    "tokenizer.save_pretrained(output_model_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7310947,
     "sourceId": 11685199,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "PFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
