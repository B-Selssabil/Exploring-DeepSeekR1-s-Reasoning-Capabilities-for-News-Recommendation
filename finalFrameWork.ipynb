{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1 - Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T16:45:07.791349Z",
     "iopub.status.busy": "2025-05-07T16:45:07.790725Z",
     "iopub.status.idle": "2025-05-07T16:45:39.467553Z",
     "shell.execute_reply": "2025-05-07T16:45:39.466979Z",
     "shell.execute_reply.started": "2025-05-07T16:45:07.791313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import pandas as pd\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2 - Loading Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T16:46:10.820229Z",
     "iopub.status.busy": "2025-05-07T16:46:10.819944Z",
     "iopub.status.idle": "2025-05-07T16:46:10.827636Z",
     "shell.execute_reply": "2025-05-07T16:46:10.826927Z",
     "shell.execute_reply.started": "2025-05-07T16:46:10.820209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/configure/config.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "# general configuration\n",
    "HGF = config['general']['HGF']\n",
    "\n",
    "\n",
    "# model configuration\n",
    "output_model_online_Desc = config['outputs']['output_model_online_Desc']\n",
    "output_model_online_Rec = config['outputs']['output_model_online_Rec']\n",
    "\n",
    "max_seq_length = config['model']['max_seq_length']\n",
    "load_in_4bit = config['model']['load_in_4bit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3 - Loading Framework Components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T16:55:20.549545Z",
     "iopub.status.busy": "2025-05-07T16:55:20.548937Z",
     "iopub.status.idle": "2025-05-07T16:56:31.260370Z",
     "shell.execute_reply": "2025-05-07T16:56:31.259549Z",
     "shell.execute_reply.started": "2025-05-07T16:55:20.549519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_desc, tokenizer_desc = FastLanguageModel.from_pretrained(\n",
    "    model_name = output_model_online_Desc,\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    token = HGF\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:03:22.177831Z",
     "iopub.status.busy": "2025-05-07T17:03:22.177222Z",
     "iopub.status.idle": "2025-05-07T17:03:36.035832Z",
     "shell.execute_reply": "2025-05-07T17:03:36.034979Z",
     "shell.execute_reply.started": "2025-05-07T17:03:22.177806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_rec, tokenizer_rec = FastLanguageModel.from_pretrained(\n",
    "    model_name = output_model_online_Rec,\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    token = HGF\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4 - Defining Prompt Template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:04:05.476021Z",
     "iopub.status.busy": "2025-05-07T17:04:05.475341Z",
     "iopub.status.idle": "2025-05-07T17:04:05.479305Z",
     "shell.execute_reply": "2025-05-07T17:04:05.478691Z",
     "shell.execute_reply.started": "2025-05-07T17:04:05.476001Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "promptDesc = \"\"\" Below is an instruction that describes a task, paired with an input that provied further context.\n",
    "Write a response that appropiately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "You are an interests analyzer. Based on the following user history, analyze their reading habits and generate a description of what kind of news articles they might be interested in reading next. \n",
    "\n",
    "### History:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "Description : \\n\n",
    "{}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:04:09.180787Z",
     "iopub.status.busy": "2025-05-07T17:04:09.180214Z",
     "iopub.status.idle": "2025-05-07T17:04:09.184580Z",
     "shell.execute_reply": "2025-05-07T17:04:09.183921Z",
     "shell.execute_reply.started": "2025-05-07T17:04:09.180759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "promptRec = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \n",
    "Write a response that appropriately completes the request. \n",
    "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
    "\n",
    "### Instruction:\n",
    "You serve as a personalized news article recommendation system. Based on the user's preference descriptions below and the candidate articles, rank the candidates using their labels.\n",
    "Output Format:\n",
    "Ranked News Articles: <START> C#, C#, ..., C# <END>\n",
    "\n",
    "### Preferences Description:\n",
    "{}\n",
    "\n",
    "### Candidates:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "<think>{} \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5 - Assembling the Framework**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:46:14.953595Z",
     "iopub.status.busy": "2025-05-07T17:46:14.953306Z",
     "iopub.status.idle": "2025-05-07T17:46:14.961312Z",
     "shell.execute_reply": "2025-05-07T17:46:14.960474Z",
     "shell.execute_reply.started": "2025-05-07T17:46:14.953576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generateDescription(history, model, tokenizer):\n",
    "    inputs = tokenizer([promptDesc.format(history, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "    outputs = model.generate(\n",
    "                input_ids=inputs.input_ids,\n",
    "                attention_mask=inputs.attention_mask,\n",
    "                max_new_tokens= 1000\n",
    "            )\n",
    "    response = tokenizer.batch_decode(outputs)\n",
    "    description = response[0].split(\"### Response:\")[1].split(\"\\nDescription : \\n\\n\\n\\n\")[1].replace(\"<｜end▁of▁sentence｜>\",\"\")\n",
    "    return description\n",
    "\n",
    "def recommendNews(description, candidates, model, tokenizer):\n",
    "\n",
    "    inputs = tokenizer([promptRec.format(description, candidates, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(\n",
    "                input_ids=inputs.input_ids,\n",
    "                attention_mask=inputs.attention_mask,\n",
    "                max_new_tokens=1000\n",
    "            )\n",
    "    response = tokenizer.batch_decode(outputs)\n",
    "    result = response[0].split(\"### Response:\")[1]\n",
    "    cot_match = re.search(r'<think>(.*?)</think>', result, re.DOTALL)\n",
    "    if cot_match:\n",
    "        cot = cot_match.group(1).strip()\n",
    "    news_match = re.search(r'Ranked News Articles\\s*:\\s*(.*)', result)\n",
    "    if news_match:\n",
    "                after_phrase = news_match.group(1)\n",
    "                rankedArticles = re.findall(r'C\\d+', after_phrase)\n",
    "\n",
    "    rankedArticles = list(dict.fromkeys(re.findall(r'C\\d+', after_phrase) + re.findall(r'C\\d+', candidates)))\n",
    "\n",
    "    return cot, rankedArticles\n",
    "\n",
    "def FrameWork(history, candidates):\n",
    "     \n",
    "    description = generateDescription(history, model_desc, tokenizer_desc)\n",
    "    cot, rankedArticles = recommendNews(description, candidates , model_rec ,tokenizer_rec)\n",
    "\n",
    "    return description, cot, rankedArticles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6 - Using the Framewrok**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:42:35.667241Z",
     "iopub.status.busy": "2025-05-07T17:42:35.666430Z",
     "iopub.status.idle": "2025-05-07T17:42:35.700645Z",
     "shell.execute_reply": "2025-05-07T17:42:35.700115Z",
     "shell.execute_reply.started": "2025-05-07T17:42:35.667218Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/datasettest/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:44:50.627388Z",
     "iopub.status.busy": "2025-05-07T17:44:50.626698Z",
     "iopub.status.idle": "2025-05-07T17:44:50.631016Z",
     "shell.execute_reply": "2025-05-07T17:44:50.630296Z",
     "shell.execute_reply.started": "2025-05-07T17:44:50.627364Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "instance = df.iloc[2]\n",
    "history = instance['history']\n",
    "candidates = instance['Candidates']\n",
    "label = instance['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T17:46:18.629664Z",
     "iopub.status.busy": "2025-05-07T17:46:18.628470Z",
     "iopub.status.idle": "2025-05-07T17:46:44.474105Z",
     "shell.execute_reply": "2025-05-07T17:46:44.473477Z",
     "shell.execute_reply.started": "2025-05-07T17:46:18.629608Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User history: \n",
      " H1: The 2019 NFL midseason MVP rankings which belongs to the category of sports and subcategory of football_nfl\n",
      "H2: Week 9 winners, losers: Russell Wilson taking lead in MVP race; Adam Gase in trouble which belongs to the category of sports and subcategory of football_nfl\n",
      "H3: Tom Brady explains why he's angry at this point in the football season which belongs to the category of sports and subcategory of football_nfl\n",
      "\n",
      "List of candidates: \n",
      " C1: Police find 26 children behind false wall at Colorado day care which belongs to the category of news and subcategory of crime\n",
      "C2: Meghan Markle's Lawyers Debunk Multiple False Tabloid Stories in New Court Documents which belongs to the category of lifestyle and subcategory of lifestyleroyals\n",
      "C3: This stately home is having the ultimate yard sale which belongs to the category of finance and subcategory of finance-real-estate\n",
      "C4: 66 Cool Tech Gifts Anyone Would Be Thrilled to Receive which belongs to the category of lifestyle and subcategory of shop-holidays\n",
      "C5: The Kardashians Face Backlash Over 'Insensitive' Family Food Fight in KUWTK Clip which belongs to the category of tv and subcategory of tv-celebrity\n",
      "C6: 3 Indiana judges suspended after a night of drinking turned into a White Castle brawl which belongs to the category of news and subcategory of us\n",
      "C7: I've been writing about tiny homes for a year and finally spent 2 nights in a 300-foot home to see what it's all about   here's how it went which belongs to the category of lifestyle and subcategory of voices\n",
      "C8: The Unlikely Star of My Family's Thanksgiving Table which belongs to the category of foodanddrink and subcategory of recipes\n",
      "C9: Opinion: Colin Kaepernick is about to get what he deserves: a chance which belongs to the category of sports and subcategory of football_nfl\n",
      "C10: Ford v Ferrari: the forgotten car at the heart of the Le Mans '66 clash which belongs to the category of autos and subcategory of autosenthusiasts\n",
      "\n",
      "Description generated: \n",
      " The user is highly engaged with NFL sports news, particularly focusing on midseason MVP rankings, team performance, and player analysis. They seem to follow prominent figures like Tom Brady and key developments in the NFL, such as the MVP race and coach Adam Gase's situation. They might enjoy reading more about NFL standings, player rankings, and major game updates as the season progresses.\n",
      "\n",
      "\n",
      "\n",
      "Chain of thought generated: \n",
      " 1. Identifying Relevant Categories: The user is highly engaged with NFL sports news, particularly focusing on midseason MVP rankings, team performance, and player analysis. Relevant categories: Sports (particularly NFL), News (crime, us), Lifestyle (royals, celebrities), etc. 2. Filtering Articles by Relevance: Relevant articles: C9 (Colin Kaepernick, NFL-related), C6 (Indiana judges, US news), C5 (Kardashians, celebrity news), C2 (Meghan Markle, royals), C1 (crime, children), C10 (autos, Ford v Ferrari), C3 (real estate, home sale), C4 (tech gifts, lifestyle), C7 (tiny homes, lifestyle), C8 (food, recipes). 3. Ranking Relevant Articles: C9 ranks first as it directly aligns with the user's interest in NFL news. C6 follows due to its connection to US news and public figures. C5 and C2 are relevant due to the user's interest in celebrities and high-profile figures. C1 ranks next as crime news is often of interest, followed by C10 for auto-related content. C3 and C7 are relevant but rank lower as they are more about real estate and lifestyle. C4 and C8 are the least relevant, focusing on tech gifts and food recipes. 4. Reordered List of Labels: ['C9', 'C6', 'C5', 'C2', 'C1', 'C10', 'C3', 'C7', 'C4', 'C8']\n",
      "\n",
      "Ranked articles: \n",
      " ['C9', 'C6', 'C5', 'C2', 'C1', 'C10', 'C3', 'C7', 'C4', 'C8']\n",
      "\n",
      "The article the user actually read next: C9\n"
     ]
    }
   ],
   "source": [
    "description, cot, ranked_Articles = FrameWork(history, candidates)\n",
    "\n",
    "print(f\"User history: \\n {history}\\n\")\n",
    "print(f\"List of candidates: \\n {candidates}\\n\")\n",
    "print(f\"Description generated: \\n {description}\\n\")\n",
    "print(f\"Chain of thought generated: \\n {cot}\\n\")\n",
    "print(f\"Ranked articles: \\n {ranked_Articles}\\n\")\n",
    "print(f\"The article the user actually read next: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7357888,
     "sourceId": 11721052,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7357926,
     "sourceId": 11721100,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7358060,
     "sourceId": 11721324,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
